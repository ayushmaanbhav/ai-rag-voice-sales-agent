# Feature Flag Configuration for Voice Agent
# This file controls which providers and features are enabled

features:
  # Speech-to-Text Configuration
  stt:
    provider: "indicconformer"  # whisper | indicconformer | sarvam
    enabled: true
    fallback: "whisper"  # Fallback provider if primary fails

  # Text-to-Speech Configuration
  tts:
    provider: "indicf5"  # piper | indicf5 | sarvam
    enabled: true
    fallback: "piper"  # Fallback provider if primary fails

  # Translation Configuration (for translation pipeline)
  translation:
    enabled: false  # Set to true for translation pipeline
    provider: "indictrans2"  # indictrans2 | google | noop
    config:
      model_size: "distilled-200M"
      device: "cpu"

  # LLM Configuration
  llm:
    provider: "ollama"  # ollama | claude | openai
    model: "qwen3:8b-q4_K_M"  # Use instruct model (not reasoning model)
    reasoning_language: "native"  # native | english
    config:
      temperature: 0.7
      max_tokens: 150
      base_url: "http://localhost:11434"

  # RAG Configuration
  rag:
    enabled: true
    reranking: false
    query_rewriting: false
    config:
      top_k: 5
      similarity_threshold: 0.7
      hybrid_weight: 0.7  # Semantic vs BM25 weight

  # Experiment Configuration
  experiments:
    architecture: "native"  # native | translation | ab_test
    ab_test_ratio: 0.5  # Ratio for A/B testing (0.5 = 50% each)
    log_all_metrics: true
    collect_human_feedback: false

# Provider-specific configurations
providers:
  whisper:
    model_path: null  # Use default HuggingFace path
    download_root: null

  indicconformer:
    model_name: "ai4bharat/indicconformer-multilingual"  # Supports 22 Indian languages
    device: "cpu"  # cpu | cuda
    batch_size: 1

  piper:
    model_directory: "/models/piper"
    use_cuda: false

  indicf5:
    model_name: "ai4bharat/IndicF5"  # Supports 11 Indian languages
    device: "cpu"  # cpu | cuda
    reference_audio: null  # Path to reference audio for voice cloning
    sample_rate: 24000

  indictrans2:
    model_name: "ai4bharat/indictrans2-indic-en-dist-200M"
    src_lang: "hin_Deva"
    tgt_lang: "eng_Latn"

  ollama:
    base_url: "http://localhost:11434"
    timeout: 60

# Logging and Metrics
observability:
  log_level: "INFO"
  metrics_enabled: true
  metrics_export_interval: 60  # seconds
  trace_requests: true
  log_latency_breakdown: true

# Performance Tuning
performance:
  max_concurrent_requests: 10
  request_timeout: 30  # seconds
  enable_caching: true
  cache_ttl: 300  # seconds
