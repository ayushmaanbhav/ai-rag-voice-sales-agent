//! IndicF5 TTS Model
//!
//! Main model that combines all components for Hindi text-to-speech synthesis:
//! 1. Text/Phoneme processing with G2P
//! 2. DiT backbone for mel spectrogram generation
//! 3. Flow matching for high-quality sampling
//! 4. Vocos vocoder for audio synthesis
//!
//! # Usage
//!
//! ```rust,ignore
//! use voice_agent_pipeline::tts::candle::IndicF5Model;
//!
//! let model = IndicF5Model::load("models/tts/IndicF5/model.safetensors")?;
//! let audio = model.synthesize("नमस्ते दुनिया", &reference_audio)?;
//! ```

#[cfg(feature = "candle")]
use candle_core::{DType, Device, Result, Tensor};
#[cfg(feature = "candle")]
use candle_nn::VarBuilder;

#[cfg(feature = "candle")]
use std::path::Path;

#[cfg(feature = "candle")]
use super::config::{FlowMatchingConfig, IndicF5Config, VocosConfig};
#[cfg(feature = "candle")]
use super::dit::DiTBackbone;
#[cfg(feature = "candle")]
use super::flow_matching::FlowMatcher;
#[cfg(feature = "candle")]
use super::mel::{MelConfig, MelSpectrogram};
#[cfg(feature = "candle")]
use super::vocos::VocosVocoder;

/// IndicF5 Text-to-Speech Model
#[cfg(feature = "candle")]
pub struct IndicF5Model {
    /// DiT backbone for mel generation
    backbone: DiTBackbone,
    /// Flow matching sampler
    flow_matcher: FlowMatcher,
    /// Vocos vocoder for audio synthesis
    vocoder: VocosVocoder,
    /// Mel spectrogram extractor
    mel_extractor: MelSpectrogram,
    /// Vocabulary for text tokenization
    vocabulary: IndicF5Vocabulary,
    /// Model configuration
    config: IndicF5Config,
    /// Device
    device: Device,
}

#[cfg(feature = "candle")]
impl IndicF5Model {
    /// Load model from SafeTensors file
    pub fn load<P: AsRef<Path>>(
        model_path: P,
        vocab_path: Option<P>,
        device: Device,
    ) -> Result<Self> {
        let config = IndicF5Config::indicf5_hindi();
        Self::load_with_config(model_path, vocab_path, config, device)
    }

    /// Load model with custom configuration
    pub fn load_with_config<P: AsRef<Path>>(
        model_path: P,
        vocab_path: Option<P>,
        config: IndicF5Config,
        device: Device,
    ) -> Result<Self> {
        // Get dtype from quantization config
        let dtype = config.quantization.to_dtype();

        // Load SafeTensors weights with specified dtype
        let vb = unsafe {
            VarBuilder::from_mmaped_safetensors(&[model_path.as_ref()], dtype, &device)?
        };

        tracing::info!(
            "Loading IndicF5 model with {:?} quantization (est. memory: {} MB)",
            config.quantization,
            config.estimated_memory() / 1024 / 1024
        );

        // Load backbone
        let backbone = DiTBackbone::load(config.clone(), vb.pp("backbone"))?;

        // Create flow matcher
        let flow_config = FlowMatchingConfig::default();
        let flow_matcher = FlowMatcher::new(flow_config);

        // Load vocoder
        let vocos_config = VocosConfig::default();
        let vocoder = VocosVocoder::load(vocos_config, vb.pp("vocoder"))?;

        // Create mel extractor
        let mel_config = MelConfig {
            sample_rate: config.sample_rate,
            n_fft: 1024,
            hop_length: config.hop_length,
            n_mels: config.n_mels,
            ..Default::default()
        };
        let mel_extractor = MelSpectrogram::new(mel_config, &device)?;

        // Load vocabulary
        let vocabulary = if let Some(path) = vocab_path {
            IndicF5Vocabulary::load(path)?
        } else {
            IndicF5Vocabulary::default_hindi()
        };

        Ok(Self {
            backbone,
            flow_matcher,
            vocoder,
            mel_extractor,
            vocabulary,
            config,
            device,
        })
    }

    /// Create a new model (for training or testing)
    pub fn new(config: IndicF5Config, vb: VarBuilder, device: Device) -> Result<Self> {
        let backbone = DiTBackbone::new(config.clone(), vb.pp("backbone"))?;

        let flow_config = FlowMatchingConfig::default();
        let flow_matcher = FlowMatcher::new(flow_config);

        let vocos_config = VocosConfig::default();
        let vocoder = VocosVocoder::new(vocos_config, vb.pp("vocoder"))?;

        let mel_config = MelConfig {
            sample_rate: config.sample_rate,
            n_fft: 1024,
            hop_length: config.hop_length,
            n_mels: config.n_mels,
            ..Default::default()
        };
        let mel_extractor = MelSpectrogram::new(mel_config, &device)?;

        let vocabulary = IndicF5Vocabulary::default_hindi();

        Ok(Self {
            backbone,
            flow_matcher,
            vocoder,
            mel_extractor,
            vocabulary,
            config,
            device,
        })
    }

    /// Synthesize speech from text
    ///
    /// Args:
    ///   text: Input text in Hindi or phoneme sequence
    ///   reference_audio: Reference audio for voice cloning [samples]
    ///
    /// Returns:
    ///   Audio samples at 24kHz
    pub fn synthesize(&self, text: &str, reference_audio: &[f32]) -> Result<Vec<f32>> {
        // Tokenize text
        let tokens = self.vocabulary.encode(text);
        let token_tensor = Tensor::from_vec(tokens.clone(), (1, tokens.len()), &self.device)?;

        // Extract mel from reference audio
        let ref_audio = Tensor::from_vec(reference_audio.to_vec(), (1, reference_audio.len()), &self.device)?;
        let ref_mel = self.mel_extractor.forward(&ref_audio)?;

        // Estimate target length based on text
        let target_len = self.estimate_mel_length(text.chars().count(), ref_mel.dim(1)?);

        // Sample mel using flow matching
        let generated_mel = self.flow_matcher.sample(
            &self.backbone,
            &token_tensor,
            &ref_mel,
            target_len,
            &self.device,
        )?;

        // Vocode to audio
        let audio = self.vocoder.forward(&generated_mel)?;

        // Convert to Vec
        audio.squeeze(0)?.to_vec1()
    }

    /// Synthesize with specific duration control
    pub fn synthesize_with_duration(
        &self,
        text: &str,
        reference_audio: &[f32],
        duration_secs: f32,
    ) -> Result<Vec<f32>> {
        let tokens = self.vocabulary.encode(text);
        let token_tensor = Tensor::from_vec(tokens.clone(), (1, tokens.len()), &self.device)?;

        let ref_audio = Tensor::from_vec(reference_audio.to_vec(), (1, reference_audio.len()), &self.device)?;
        let ref_mel = self.mel_extractor.forward(&ref_audio)?;

        let target_len = self.config.frames_for_duration(duration_secs);

        let generated_mel = self.flow_matcher.sample(
            &self.backbone,
            &token_tensor,
            &ref_mel,
            target_len,
            &self.device,
        )?;

        let audio = self.vocoder.forward(&generated_mel)?;
        audio.squeeze(0)?.to_vec1()
    }

    /// Synthesize streaming (yields audio chunks)
    pub fn synthesize_streaming<F>(
        &self,
        text: &str,
        reference_audio: &[f32],
        chunk_callback: F,
    ) -> Result<()>
    where
        F: Fn(&[f32]) -> bool,  // Returns false to stop
    {
        // For streaming, we could:
        // 1. Split text into sentences/phrases
        // 2. Generate mel for each segment
        // 3. Vocode and yield chunks

        let sentences = self.split_text_for_streaming(text);
        let ref_audio = Tensor::from_vec(reference_audio.to_vec(), (1, reference_audio.len()), &self.device)?;
        let ref_mel = self.mel_extractor.forward(&ref_audio)?;

        for sentence in sentences {
            let tokens = self.vocabulary.encode(&sentence);
            if tokens.is_empty() {
                continue;
            }

            let token_tensor = Tensor::from_vec(tokens.clone(), (1, tokens.len()), &self.device)?;
            let target_len = self.estimate_mel_length(sentence.chars().count(), ref_mel.dim(1)?);

            let generated_mel = self.flow_matcher.sample(
                &self.backbone,
                &token_tensor,
                &ref_mel,
                target_len,
                &self.device,
            )?;

            let audio = self.vocoder.forward(&generated_mel)?;
            let samples: Vec<f32> = audio.squeeze(0)?.to_vec1()?;

            if !chunk_callback(&samples) {
                break;
            }
        }

        Ok(())
    }

    /// Estimate mel spectrogram length from text length
    fn estimate_mel_length(&self, text_len: usize, ref_len: usize) -> usize {
        // Rough estimate: ~10 frames per character for Hindi
        // Add reference length for in-context learning
        let estimated = text_len * 10 + ref_len;
        estimated.max(ref_len + 50)  // Minimum 50 frames of generation
    }

    /// Split text for streaming synthesis
    fn split_text_for_streaming(&self, text: &str) -> Vec<String> {
        // Split on sentence boundaries
        text.split(|c| c == '।' || c == '.' || c == '?' || c == '!')
            .map(|s| s.trim().to_string())
            .filter(|s| !s.is_empty())
            .collect()
    }

    /// Get model configuration
    pub fn config(&self) -> &IndicF5Config {
        &self.config
    }

    /// Get device
    pub fn device(&self) -> &Device {
        &self.device
    }

    /// Set inference parameters
    pub fn set_inference_params(&mut self, num_steps: usize, cfg_strength: f32) {
        self.flow_matcher.set_num_steps(num_steps);
        self.flow_matcher.set_cfg_strength(cfg_strength);
    }
}

/// Vocabulary for IndicF5
#[cfg(feature = "candle")]
pub struct IndicF5Vocabulary {
    char_to_id: std::collections::HashMap<char, u32>,
    id_to_char: std::collections::HashMap<u32, char>,
    special_tokens: SpecialTokens,
}

#[cfg(feature = "candle")]
struct SpecialTokens {
    pad: u32,
    unk: u32,
    bos: u32,
    eos: u32,
}

#[cfg(feature = "candle")]
impl IndicF5Vocabulary {
    /// Load vocabulary from file
    pub fn load<P: AsRef<Path>>(path: P) -> Result<Self> {
        use std::io::{BufRead, BufReader};

        let file = std::fs::File::open(path.as_ref())
            .map_err(|e| candle_core::Error::Msg(format!("Failed to open vocab file: {}", e)))?;

        let reader = BufReader::new(file);
        let mut char_to_id = std::collections::HashMap::new();
        let mut id_to_char = std::collections::HashMap::new();

        for (idx, line) in reader.lines().enumerate() {
            let line = line.map_err(|e| candle_core::Error::Msg(e.to_string()))?;
            let ch = line.chars().next().unwrap_or(' ');
            char_to_id.insert(ch, idx as u32);
            id_to_char.insert(idx as u32, ch);
        }

        Ok(Self {
            char_to_id,
            id_to_char,
            special_tokens: SpecialTokens {
                pad: 0,
                unk: 1,
                bos: 2,
                eos: 3,
            },
        })
    }

    /// Create default Hindi vocabulary
    pub fn default_hindi() -> Self {
        let mut char_to_id = std::collections::HashMap::new();
        let mut id_to_char = std::collections::HashMap::new();

        // Special tokens: PAD, UNK, BOS, EOS
        // Use Unicode private use area for special tokens
        let special_chars = ['\u{0000}', '\u{FFFD}', '\u{0002}', '\u{0003}'];
        for (i, &ch) in special_chars.iter().enumerate() {
            char_to_id.insert(ch, i as u32);
            id_to_char.insert(i as u32, ch);
        }

        // Hindi/Devanagari characters (basic set)
        let hindi_chars: Vec<char> = ('अ'..='ह')
            .chain('ा'..='ौ')
            .chain(['्', 'ं', 'ः', '़', 'ॐ', '।', '॥'])
            .chain('०'..='९')
            .chain('a'..='z')
            .chain('A'..='Z')
            .chain('0'..='9')
            .chain(['.', ',', '?', '!', '-', '\'', '"', '(', ')', ' '])
            .collect();

        for (i, ch) in hindi_chars.iter().enumerate() {
            let id = (i + 4) as u32;
            char_to_id.insert(*ch, id);
            id_to_char.insert(id, *ch);
        }

        Self {
            char_to_id,
            id_to_char,
            special_tokens: SpecialTokens {
                pad: 0,
                unk: 1,
                bos: 2,
                eos: 3,
            },
        }
    }

    /// Encode text to token IDs
    pub fn encode(&self, text: &str) -> Vec<u32> {
        let mut tokens = vec![self.special_tokens.bos];

        for ch in text.chars() {
            let id = self.char_to_id.get(&ch).copied().unwrap_or(self.special_tokens.unk);
            tokens.push(id);
        }

        tokens.push(self.special_tokens.eos);
        tokens
    }

    /// Decode token IDs to text
    pub fn decode(&self, tokens: &[u32]) -> String {
        tokens
            .iter()
            .filter(|&&id| id != self.special_tokens.pad
                && id != self.special_tokens.bos
                && id != self.special_tokens.eos)
            .filter_map(|&id| self.id_to_char.get(&id))
            .collect()
    }

    /// Get vocabulary size
    pub fn vocab_size(&self) -> usize {
        self.char_to_id.len()
    }
}

/// Phoneme-based vocabulary for better synthesis quality
#[cfg(feature = "candle")]
pub struct PhonemeVocabulary {
    phoneme_to_id: std::collections::HashMap<String, u32>,
    id_to_phoneme: std::collections::HashMap<u32, String>,
}

#[cfg(feature = "candle")]
impl PhonemeVocabulary {
    /// Create from phoneme list
    pub fn from_phonemes(phonemes: &[&str]) -> Self {
        let mut phoneme_to_id = std::collections::HashMap::new();
        let mut id_to_phoneme = std::collections::HashMap::new();

        for (i, &phoneme) in phonemes.iter().enumerate() {
            let id = i as u32;
            phoneme_to_id.insert(phoneme.to_string(), id);
            id_to_phoneme.insert(id, phoneme.to_string());
        }

        Self {
            phoneme_to_id,
            id_to_phoneme,
        }
    }

    /// Encode phoneme sequence
    pub fn encode(&self, phonemes: &[&str]) -> Vec<u32> {
        phonemes
            .iter()
            .filter_map(|&p| self.phoneme_to_id.get(p))
            .copied()
            .collect()
    }

    /// Decode to phoneme sequence
    pub fn decode(&self, tokens: &[u32]) -> Vec<String> {
        tokens
            .iter()
            .filter_map(|&id| self.id_to_phoneme.get(&id))
            .cloned()
            .collect()
    }
}

// Non-Candle stubs
#[cfg(not(feature = "candle"))]
pub struct IndicF5Model;

#[cfg(not(feature = "candle"))]
pub struct IndicF5Vocabulary;

#[cfg(not(feature = "candle"))]
pub struct PhonemeVocabulary;

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_indicf5_module_exists() {
        // Verify module compiles
    }

    #[cfg(feature = "candle")]
    #[test]
    fn test_vocabulary_encode_decode() {
        let vocab = IndicF5Vocabulary::default_hindi();

        let text = "नमस्ते";
        let tokens = vocab.encode(text);
        assert!(tokens.len() > 2); // At least BOS + text + EOS

        // Decode should recover the text (minus special tokens)
        let decoded = vocab.decode(&tokens);
        // Note: Some characters may be UNK if not in vocab
        assert!(!decoded.is_empty());
    }
}
